{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T12:48:12.561963Z",
     "start_time": "2019-05-15T12:48:01.969305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\alexander\\anaconda3\\lib\\site-packages (0.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T21:11:09.725204Z",
     "start_time": "2019-04-02T21:11:01.222044Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.models as lm\n",
    "\n",
    "from ssd_model.keras_layer_L2Normalization import L2Normalization\n",
    "from ssd_model.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from ssd_model.keras_layer_DecodeDetections import DecodeDetections\n",
    "from ssd_model.keras_ssd_loss import SSDLoss\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model = lm.load_model('ssd_300.h5', custom_objects={'L2Normalization' : L2Normalization, 'AnchorBoxes':AnchorBoxes, 'DecodeDetections':DecodeDetections,\n",
    "                                                   'compute_loss':ssd_loss.compute_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T13:24:22.366863Z",
     "start_time": "2019-04-03T13:24:22.362852Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import operator\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T13:37:12.937395Z",
     "start_time": "2019-04-03T13:37:12.933403Z"
    }
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'video' : 'video/campus4-c0.avi',\n",
    "    'tracker' : 'kcf',\n",
    "    'frame_skip': 3,\n",
    "    'confidence': 0.3,\n",
    "    'ttl' : 23,\n",
    "    'min_dist' : 190\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T13:37:14.007778Z",
     "start_time": "2019-04-03T13:37:14.003777Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize a dictionary that maps strings to their corresponding\n",
    "# OpenCV object tracker implementations\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "  \"csrt\": cv2.TrackerCSRT_create,\n",
    "  \"kcf\": cv2.TrackerKCF_create,\n",
    "  \"boosting\": cv2.TrackerBoosting_create,\n",
    "  \"mil\": cv2.TrackerMIL_create,\n",
    "  \"tld\": cv2.TrackerTLD_create,\n",
    "  \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "  \"mosse\": cv2.TrackerMOSSE_create\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T13:37:14.313863Z",
     "start_time": "2019-04-03T13:37:14.306868Z"
    }
   },
   "outputs": [],
   "source": [
    "# if a video path was not supplied, grab the reference to the web cam\n",
    "if not args.get('video', False):\n",
    "    print(\"[INFO] starting video stream...\")\n",
    "    vs = VideoStream(src=0).start()\n",
    "    time.sleep(1.0)\n",
    " \n",
    "# otherwise, grab a reference to the video file\n",
    "else:\n",
    "    vs = cv2.VideoCapture(args['video'])\n",
    " \n",
    "# initialize the FPS throughput estimator\n",
    "fps = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T13:37:15.010055Z",
     "start_time": "2019-04-03T13:37:15.004057Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trackable_object():\n",
    "    def __init__(self, objectID, box, isTracked):\n",
    "        self.objectID = objectID\n",
    "        self.box = box\n",
    "        self.prev_box = np.array([0,0,0,0])\n",
    "        self.future_box = np.array([0,0,0,0])\n",
    "        self.centroid = get_centroid(box)\n",
    "        self.isTracked = isTracked\n",
    "        self.hasAssignedBox = False\n",
    "        self.ttl = args.get('ttl') \n",
    "    \n",
    "    def update_centroid(self):\n",
    "        self.centroid = get_centroid(self.box)\n",
    "        \n",
    "    def get_diag_len(self):\n",
    "        return np.linalg.norm(np.array(box[0],box[1])-np.array(box[2],box[3]))\n",
    "    \n",
    "    def compute_future_box(self):\n",
    "        diff = get_difference(self.prev_box, self.box)\n",
    "        self.future_box = self.box + diff\n",
    "        \n",
    "    def update(self):\n",
    "        self.update_centroid()\n",
    "        self.compute_future_box()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T13:37:15.290392Z",
     "start_time": "2019-04-03T13:37:15.282413Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_centroid(box):\n",
    "        x = int(np.abs((box[2]-box[0])/2))\n",
    "        y = int(np.abs((box[3]-box[1])/2))\n",
    "        if box[0] < box[2]:\n",
    "             x+= box[0]\n",
    "        else: x+=box[2]\n",
    "        if box[1] < box[3]:\n",
    "            y+= box[1]\n",
    "        else: y+=box[3]\n",
    "        return x, y\n",
    "    \n",
    "def get_centroid_distance(c1,c2):\n",
    "    return np.linalg.norm(np.array(c1)-np.array(c2))\n",
    "\n",
    "def get_difference(box1, box2):\n",
    "    lu1 = np.array([box1[0],box1[1]])\n",
    "    rb1 = np.array([box1[2],box1[3]])\n",
    "    \n",
    "    lu2 = np.array([box2[0],box2[1]])\n",
    "    rb2 = np.array([box2[2],box2[3]])\n",
    "    \n",
    "    return np.hstack((lu2-lu1, rb2-rb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T13:37:15.566407Z",
     "start_time": "2019-04-03T13:37:15.554428Z"
    }
   },
   "outputs": [],
   "source": [
    "def roi_from_box(box):\n",
    "    return (box[0],box[1],box[2]-box[0],box[3]-box[1])\n",
    "def box_from_roi(roi):\n",
    "    return np.array([roi[0],roi[1],roi[0]+roi[2],roi[1]+roi[3]])\n",
    "\n",
    "def get_ang_dist(box1, box2):\n",
    "    distanse = 0\n",
    "    lu1 = (box1[0],box1[1])\n",
    "    ru1 = (box1[2],box1[0])\n",
    "    rb1 = (box1[2],box1[3])\n",
    "    lb1 = (box1[0],box1[3])\n",
    "    \n",
    "    lu2 = (box2[0],box2[1])\n",
    "    ru2 = (box2[2],box2[0])\n",
    "    rb2 = (box2[2],box2[3])\n",
    "    lb2 = (box2[0],box2[3])\n",
    "    \n",
    "    distanse += np.linalg.norm(np.array(lu1)-np.array(lu2))\n",
    "    distanse += np.linalg.norm(np.array(ru1)-np.array(ru2))\n",
    "    distanse += np.linalg.norm(np.array(rb1)-np.array(rb2))\n",
    "    distanse += np.linalg.norm(np.array(lb1)-np.array(lb2))\n",
    "    return distanse\n",
    "\n",
    "\n",
    "def get_intersection(bb1, bb2):\n",
    "  \n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1[0], bb2[0])\n",
    "    y_top = max(bb1[1], bb2[1])\n",
    "    x_right = min(bb1[2], bb2[2])\n",
    "    y_bottom = min(bb1[3], bb2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    return intersection_area / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T13:37:16.534033Z",
     "start_time": "2019-04-03T13:37:16.530033Z"
    }
   },
   "outputs": [],
   "source": [
    "def sort_dict(dictionary):\n",
    "    sorted_dict = {}\n",
    "    sorted_list = sorted(trackable_objects.values(), key=operator.attrgetter('ttl'))\n",
    "    for o in sorted_list:\n",
    "        sorted_dict[o.objectID] = o\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T13:38:51.520841Z",
     "start_time": "2019-04-03T13:37:33.237324Z"
    }
   },
   "outputs": [],
   "source": [
    "W = 300\n",
    "H = 300\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# out = cv2.VideoWriter('output_0.avi',fourcc, 24.0, (300,300))\n",
    "\n",
    "\n",
    "trackable_objects = {} # dict of trackable objects 'id':TrackableObject\n",
    "frames_processed = 0\n",
    "\n",
    "fps = FPS().start()\n",
    "\n",
    "multitracker = cv2.MultiTracker_create()\n",
    "\n",
    "\n",
    "while True:\n",
    "    # get the frame\n",
    "    frame = vs.read()\n",
    "    frame = frame[1] if args.get(\"video\", False) else frame\n",
    "    \n",
    "    # if no frame -> break\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    # resize frame to fit into SSD\n",
    "    frame = cv2.resize(frame,(300,300))\n",
    "    \n",
    "    status = 'Waiting'\n",
    "    boxes = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    # DETECTION\n",
    "    \n",
    "    if frames_processed % args['frame_skip'] == 0:\n",
    "        status = 'Detecting'\n",
    "        \n",
    "        # Get list of predictions\n",
    "        y_pred = model.predict(np.reshape(frame,(1,W,H,3)))\n",
    "        \n",
    "        # Sort out unconfident and non-person predictions\n",
    "        y_pred_thresh = []\n",
    "        for pred in y_pred[0]:\n",
    "            if pred[0]==3 and pred[1]>args['confidence']:\n",
    "                y_pred_thresh.append(pred)\n",
    "        \n",
    " \n",
    "        trackable_objects = sort_dict(trackable_objects)\n",
    "    \n",
    "        # Run through every prediction and assign an Object to it.\n",
    "        all_boxes = []\n",
    "        for box in y_pred_thresh:\n",
    "            \n",
    "            # Get values from box\n",
    "            (cls,_,xmin,ymin,xmax,ymax) = [int(val) for val in box]\n",
    "\n",
    "            # Draw green rectangle for current box\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "            \n",
    "            # Append all_boxes\n",
    "            all_boxes.append((xmin,ymin,xmax,ymax))\n",
    "            # Understand which objects are already tracked\n",
    "            min_dist = args.get('min_dist')\n",
    "            min_id = 999\n",
    "            \n",
    "            # Set current box to NotTracked\n",
    "            isBoxTracked = False\n",
    "\n",
    "            # Look for an appropriate object for current box\n",
    "            for (objectID, obj) in trackable_objects.items(): \n",
    "\n",
    "                # Calculate distance to object\n",
    "                cur_dist = get_ang_dist(obj.box,all_boxes[-1])\n",
    "        \n",
    "                # If Object is NOT Tracked and closer than others and not dead\n",
    "                # set min_id to this object id\n",
    "                if  cur_dist < min_dist and obj.isTracked == False and obj.ttl > 0:\n",
    "                    min_dist = cur_dist\n",
    "                    min_id = objectID\n",
    "                    isBoxTracked = True\n",
    "                    \n",
    "            # If the object was found, change its location, ttl, isTracked and centroid.\n",
    "            if isBoxTracked:\n",
    "                trackable_objects.get(min_id).ttl = args.get('ttl') - 1 \n",
    "                trackable_objects.get(min_id).isTracked = True\n",
    "                trackable_objects.get(min_id).prev_box = trackable_objects.get(min_id).box\n",
    "                trackable_objects.get(min_id).box = all_boxes[-1]\n",
    "                trackable_objects.get(min_id).update()\n",
    "                \n",
    "            # If there is no appropriate Object for current box, create new Object\n",
    "            else:\n",
    "                trackable_objects[len(trackable_objects)] = Trackable_object(box=all_boxes[-1], isTracked=True,objectID=len(trackable_objects))\n",
    "       \n",
    "        \n",
    "        \n",
    "        # After updating all objects. Create multitracker and track every object.\n",
    "        multitracker = cv2.MultiTracker_create()\n",
    "        \n",
    "        # Sort objects by ttl\n",
    "        trackable_objects = sort_dict(trackable_objects)\n",
    "\n",
    "    \n",
    "        # Assign tracker to objects\n",
    "        for (objectID, obj) in trackable_objects.items():\n",
    "            \n",
    "            if obj.isTracked and obj.ttl>0:\n",
    "                tracker = OPENCV_OBJECT_TRACKERS[args[\"tracker\"]]()\n",
    "                multitracker.add(tracker, frame, roi_from_box((obj.box[0],obj.box[1],obj.box[2],obj.box[3])))\n",
    "                obj.isTracked = False\n",
    "                obj.ttl -= 1\n",
    "            else:\n",
    "                # Check if object is overlaped by another object. If so, ttl+=1\n",
    "                for (temp_objectID, temp_obj) in trackable_objects.items() :\n",
    "                    if get_intersection(obj.box,temp_obj.box) > 0.6 and objectID != temp_objectID and temp_obj.ttl>=0 and obj.ttl>=0:\n",
    "                        if obj.get_diag_len() > temp_obj.get_diag_len():\n",
    "                            temp_obj.ttl+=1\n",
    "                        else: obj.ttl+=0.5\n",
    "                        break\n",
    "                        \n",
    "                obj.ttl -= 1\n",
    "                \n",
    "                # If the objects is still alive, assign tracker\n",
    "                if obj.ttl>0:\n",
    "                    tracker = OPENCV_OBJECT_TRACKERS[args[\"tracker\"]]()\n",
    "                    multitracker.add(tracker, frame, roi_from_box((obj.box[0],obj.box[1],obj.box[2],obj.box[3])))              \n",
    "        \n",
    "        \n",
    "    # TRACKING   \n",
    "    \n",
    "    else:\n",
    "        status = 'Tracking'\n",
    "        \n",
    "        # Get boxes from tracekrs\n",
    "        (success, boxes_pred) = multitracker.update(frame)\n",
    "\n",
    "        for (objectID, obj) in trackable_objects.items():\n",
    "            obj.hasAssignedBox = False\n",
    "        \n",
    "        # Array to handle 1-1 box-object\n",
    "        taken_boxes = np.zeros(len(boxes_pred))\n",
    "     \n",
    "        boxes_pred = np.array(boxes_pred)\n",
    "        boxes_pred = boxes_pred.astype(int)\n",
    "\n",
    "        trackable_objects = sort_dict(trackable_objects)\n",
    "\n",
    "        # Assign box for each object\n",
    "        for (objectID, obj) in trackable_objects.items():\n",
    "            if obj.ttl > 0:\n",
    "                min_dist = args.get('min_dist')\n",
    "                cur_box = (0,0,0,0)\n",
    "                box_id = 1337\n",
    "                \n",
    "                # Find closest box\n",
    "                for i in range(len(boxes_pred)): \n",
    "                    if taken_boxes[i] == 0:\n",
    "                        cur_dist = get_ang_dist(box_from_roi(boxes_pred[i]), obj.future_box)\n",
    "                        if cur_dist < min_dist:\n",
    "                            min_dist = cur_dist\n",
    "                            obj.hasAssignedBox = True\n",
    "                            cur_box = boxes_pred[i]\n",
    "                            box_id = i\n",
    "                \n",
    "                # Assign box to object is found\n",
    "                if obj.hasAssignedBox:\n",
    "                    obj.prev_box = obj.box\n",
    "                    obj.box = (cur_box[0],cur_box[1],cur_box[0]+cur_box[2],cur_box[1]+cur_box[3])\n",
    "                    obj.update()\n",
    "                    taken_boxes[box_id] = 1\n",
    "\n",
    "                cv2.putText(frame, '%d'%(obj.objectID), (obj.box[0],obj.box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(25,111,255),2)\n",
    "                cv2.rectangle(frame,(obj.box[0],obj.box[1]),(obj.box[2],obj.box[3]),(0,0,255),2)\n",
    "                \n",
    "                # This shows future box\n",
    "#                 cv2.rectangle(frame,(obj.future_box[0],obj.future_box[1]),(obj.future_box[2],obj.future_box[3]),(255,0,50),2)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    cv2.putText(frame, 'Status: '+str(status), (10,10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,255),1)\n",
    "    cv2.putText(frame, 'Frame: '+str(frames_processed), (10,40), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,255),1)\n",
    "    \n",
    "#     out.write(frame)\n",
    "    \n",
    "    cv2.imshow('Frame', frame)\n",
    "   \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "    frames_processed+=1\n",
    "    fps.update()\n",
    "\n",
    "vs.release()       \n",
    "# out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

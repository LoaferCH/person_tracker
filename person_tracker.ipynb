{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:01:28.343609Z",
     "start_time": "2019-05-15T13:01:28.340610Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'video' : 'video/campus4-c0.avi',\n",
    "    'tracker' : 'kcf',\n",
    "    'frame_skip': 3,\n",
    "    'confidence': 0.3,\n",
    "    'ttl' : 23,\n",
    "    'min_dist' : 190\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:01:29.506487Z",
     "start_time": "2019-05-15T13:01:29.411531Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'track_objects_in_video' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-dd0cd4a1e8d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrack_objects_in_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_show\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_save\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'track_objects_in_video' is not defined"
     ]
    }
   ],
   "source": [
    "track_objects_in_video(to_show=True, to_save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run everything below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:06.561032Z",
     "start_time": "2019-05-15T13:01:57.835779Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.models as lm\n",
    "\n",
    "from ssd_model.keras_layer_L2Normalization import L2Normalization\n",
    "from ssd_model.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from ssd_model.keras_layer_DecodeDetections import DecodeDetections\n",
    "from ssd_model.keras_ssd_loss import SSDLoss\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model = lm.load_model('ssd_model/ssd_300.h5', custom_objects={'L2Normalization' : L2Normalization, 'AnchorBoxes':AnchorBoxes, 'DecodeDetections':DecodeDetections,\n",
    "                                                   'compute_loss':ssd_loss.compute_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:12.654579Z",
     "start_time": "2019-05-15T13:02:12.626591Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import operator\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:12.909780Z",
     "start_time": "2019-05-15T13:02:12.906767Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'video' : 'video/campus4-c0.avi',\n",
    "    'tracker' : 'kcf',\n",
    "    'frame_skip': 3,\n",
    "    'confidence': 0.3,\n",
    "    'ttl' : 23,\n",
    "    'min_dist' : 190\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:13.911525Z",
     "start_time": "2019-05-15T13:02:13.907529Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize a dictionary that maps strings to their corresponding\n",
    "# OpenCV object tracker implementations\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "  \"csrt\": cv2.TrackerCSRT_create,\n",
    "  \"kcf\": cv2.TrackerKCF_create,\n",
    "  \"boosting\": cv2.TrackerBoosting_create,\n",
    "  \"mil\": cv2.TrackerMIL_create,\n",
    "  \"tld\": cv2.TrackerTLD_create,\n",
    "  \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "  \"mosse\": cv2.TrackerMOSSE_create\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:15.477263Z",
     "start_time": "2019-05-15T13:02:15.467267Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trackable_object():\n",
    "    \"\"\"Trackable object describes a person in the frame\n",
    "    Attributes\n",
    "    -------\n",
    "    object_id : int\n",
    "        Id of the object\n",
    "    box : np.array\n",
    "        Position of the object. \n",
    "        x1, x2 = left upper (x, y)\n",
    "        x3, x4 = right bottom (x, y)\n",
    "    prev_box : np.array\n",
    "        Previous position of the object. \n",
    "        x1, x2 = left upper (x, y)\n",
    "        x3, x4 = right bottom (x, y)\n",
    "    future_box : np.array\n",
    "        Predicted next position of the object. \n",
    "        x1, x2 = left upper (x, y)\n",
    "        x3, x4 = right bottom (x, y)\n",
    "    is_tracked : bool\n",
    "        Indicates if the object has assigned tracker.\n",
    "    has_assigned_box : bool\n",
    "        Indicates if the object has assigned box. \n",
    "    ttl : int\n",
    "        Time To Live of the object. TTL is decreasing every frame. When ttl is less than 0, object is considered to be dead and will not be tracked. TTL is updated every time, the object was successfully detected.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, object_id, box, is_tracked):\n",
    "        self.object_id = object_id\n",
    "        self.box = box\n",
    "        self.prev_box = np.array([0,0,0,0])\n",
    "        self.future_box = np.array([0,0,0,0])\n",
    "        self.is_tracked = is_tracked\n",
    "        self.has_assigned_box = False\n",
    "        self.ttl = parameters.get('ttl') \n",
    "     \n",
    "    def get_diag_len(self):\n",
    "        \"\"\"Calculates the diagonal length of the object box.\n",
    "            Returns\n",
    "            -------\n",
    "            Diagonal length : float\n",
    "            \n",
    "        \"\"\"\n",
    "        return np.linalg.norm(np.array(self.box[0],self.box[1])-np.array(self.box[2],self.box[3]))\n",
    "    \n",
    "    def compute_future_box(self):\n",
    "        ''' Computes future box of the object, by adding difference of previous and current box to current box.'''\n",
    "        diff = get_difference(self.prev_box, self.box)\n",
    "        self.future_box = self.box + diff\n",
    "        \n",
    "    def update(self,ttl_n, is_tracked, box):\n",
    "        \"\"\"Updates object's ttl, is_tracked, prev_box, box and future_box. \n",
    "        \n",
    "            Parameters\n",
    "            -------\n",
    "            ttl_n : int\n",
    "                ttl to assign\n",
    "            is_tracked : bool\n",
    "                set if object is tracked\n",
    "            box : np.array\n",
    "                new object position\n",
    "                \n",
    "        \"\"\"\n",
    "        self.ttl = ttl_n\n",
    "        self.is_tracked = is_tracked\n",
    "        self.prev_box = self.box\n",
    "        self.box = box\n",
    "        self.compute_future_box()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:16.010733Z",
     "start_time": "2019-05-15T13:02:15.994740Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_difference(box1, box2):\n",
    "    \"\"\"Computes the shift from box1 to box2\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    box1 : np.array\n",
    "        First box. Considered to be previous location.\n",
    "    box2 : np.array\n",
    "        Second box. Considered to be current location.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (s1, s2) : touple\n",
    "        shift on (x, y)\n",
    "        \n",
    "    \"\"\"\n",
    "    lu1 = np.array([box1[0],box1[1]])\n",
    "    rb1 = np.array([box1[2],box1[3]])\n",
    "    \n",
    "    lu2 = np.array([box2[0],box2[1]])\n",
    "    rb2 = np.array([box2[2],box2[3]])\n",
    "    \n",
    "    return np.hstack((lu2-lu1, rb2-rb1))\n",
    "\n",
    "def roi_from_box(box):\n",
    "    \"\"\"Converts box (x1, y1, x2, y2) to roi (x1, y1, x1+w, y1+h)\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    box : np.array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    roi : tuple\n",
    "    \n",
    "    \"\"\"\n",
    "    return (box[0],box[1],box[2]-box[0],box[3]-box[1])\n",
    "\n",
    "def box_from_roi(roi):\n",
    "    \"\"\"Converts roi (x1, y1, x1+w, y1+h) to box (x1, y1, x2, y2)\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    roi : tuple\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    box : np.array\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.array([roi[0],roi[1],roi[0]+roi[2],roi[1]+roi[3]])\n",
    "\n",
    "def get_ang_dist(box1, box2):\n",
    "    \"\"\"Computes angular distanse. Sum of distanses from correspomding angles.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    box1 : np.array\n",
    "    box2 : np.array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    distance : float\n",
    "    \n",
    "    \"\"\"\n",
    "    distanse = 0\n",
    "    lu1 = (box1[0],box1[1])\n",
    "    ru1 = (box1[2],box1[0])\n",
    "    rb1 = (box1[2],box1[3])\n",
    "    lb1 = (box1[0],box1[3])\n",
    "    \n",
    "    lu2 = (box2[0],box2[1])\n",
    "    ru2 = (box2[2],box2[0])\n",
    "    rb2 = (box2[2],box2[3])\n",
    "    lb2 = (box2[0],box2[3])\n",
    "    \n",
    "    distanse += np.linalg.norm(np.array(lu1)-np.array(lu2))\n",
    "    distanse += np.linalg.norm(np.array(ru1)-np.array(ru2))\n",
    "    distanse += np.linalg.norm(np.array(rb1)-np.array(rb2))\n",
    "    distanse += np.linalg.norm(np.array(lb1)-np.array(lb2))\n",
    "    \n",
    "    return distanse\n",
    "\n",
    "\n",
    "def get_intersection(bb1, bb2):\n",
    "    \"\"\"Computes intersection of two boxes. Returns interection of smaller box. So if the box is inside of another box, returns 1.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    bb1 : np.array\n",
    "    bb2 : np.array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    intersection area : float\n",
    "        from 0.0 to 1.0\n",
    "    \"\"\"\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1[0], bb2[0])\n",
    "    y_top = max(bb1[1], bb2[1])\n",
    "\n",
    "    x_right = min(bb1[2], bb2[2])\n",
    "    y_bottom = min(bb1[3], bb2[3])\n",
    "    \n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "    \n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n",
    "    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n",
    "    \n",
    "    # Divide intersection on smaller box.\n",
    "    return intersection_area / min(bb1_area, bb2_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:18.417008Z",
     "start_time": "2019-05-15T13:02:18.409995Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_create_objects(trackable_objects, bbox):\n",
    "    \"\"\" Method finds the closest object to the box and assignes this box to the object.\n",
    "    If no object found, new object is created.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    trackable_objects : dict\n",
    "        Dictionary of all trackable objects.\n",
    "    bbox : np.array\n",
    "        Box that is to be assigned to an object.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Understand which objects are already tracked\n",
    "    min_dist = parameters.get('min_dist')\n",
    "    min_id = 999\n",
    "    # Set current box to NotTracked\n",
    "    is_box_tracked = False\n",
    "    # Look for an appropriate object for current box\n",
    "    for (object_id, obj) in trackable_objects.items(): \n",
    "        # Calculate distance to object\n",
    "        cur_dist = get_ang_dist(obj.box,bbox)\n",
    "        # If Object is NOT Tracked and closer than others and not dead\n",
    "        # set min_id to this object id\n",
    "        if  cur_dist < min_dist and obj.is_tracked == False and obj.ttl > 0:\n",
    "            min_dist = cur_dist\n",
    "            min_id = object_id\n",
    "            is_box_tracked = True\n",
    "\n",
    "    # If the object was found, change its location, ttl, is_tracked and centroid.\n",
    "    if is_box_tracked:\n",
    "        trackable_objects.get(min_id).update(parameters['ttl'],True, bbox)\n",
    "\n",
    "    # If there is no appropriate Object for current box, create new Object\n",
    "    else:\n",
    "        trackable_objects[len(trackable_objects)] = Trackable_object(box=bbox, is_tracked=True,object_id=len(trackable_objects))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:18.671879Z",
     "start_time": "2019-05-15T13:02:18.661882Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_tracker_to_object(multitracker, trackable_objects, frame):\n",
    "    \"\"\" Method assignes new tracker to every is_tracked and alive object for trackable_objects.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    multitracker : cv2.MultiTracker\n",
    "        Multitracker object. New trackers are added there.\n",
    "    trackable_objects : dict\n",
    "        Dictionary of trackable objects.\n",
    "    frame : Image\n",
    "        Current video frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Assign tracker to objects\n",
    "    for (object_id, obj) in trackable_objects.items():\n",
    "\n",
    "        if obj.is_tracked and obj.ttl>0:\n",
    "            tracker = OPENCV_OBJECT_TRACKERS[parameters[\"tracker\"]]()\n",
    "            multitracker.add(tracker, frame, roi_from_box((obj.box[0],obj.box[1],obj.box[2],obj.box[3])))\n",
    "            obj.is_tracked = False\n",
    "            obj.ttl -= 1\n",
    "        else:\n",
    "            # Check if object is overlaped by another object. If so, ttl+=1\n",
    "            for (temp_object_id, temp_obj) in trackable_objects.items() :\n",
    "                if get_intersection(obj.box,temp_obj.box) > 0.6 and object_id != temp_object_id and temp_obj.ttl>=0 and obj.ttl>=0:\n",
    "                    if obj.get_diag_len() < temp_obj.get_diag_len():\n",
    "                        obj.ttl+=1\n",
    "                    else: temp_obj.ttl+=0.5\n",
    "                    break\n",
    "\n",
    "            obj.ttl -= 1\n",
    "\n",
    "            # If the objects is still alive, assign tracker\n",
    "            if obj.ttl>0:\n",
    "                tracker = OPENCV_OBJECT_TRACKERS[parameters['tracker']]()\n",
    "                multitracker.add(tracker, frame, roi_from_box((obj.box[0],obj.box[1],obj.box[2],obj.box[3])))              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:18.897811Z",
     "start_time": "2019-05-15T13:02:18.890814Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect(frame, trackable_objects):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    frame : image\n",
    "        Current video frame.\n",
    "    trackable_objects : dict\n",
    "        Dictionary of trackable objects.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    multitracker : cv2.MultiTracker\n",
    "        Multitracker object, that containes trackers.\n",
    "        \n",
    "    boxes_to_draw : list\n",
    "        List of boxes found. May be used for visualization.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    status = 'Detecting'\n",
    "    \n",
    "    boxes_to_draw = []\n",
    "\n",
    "    # Get list of predictions\n",
    "    y_pred = model.predict(np.reshape(frame,(1,300,300,3)))\n",
    "\n",
    "    # Sort out unconfident and non-person predictions\n",
    "    y_pred_thresh = []\n",
    "    for pred in y_pred[0]:\n",
    "        if pred[0]==3 and pred[1]>parameters['confidence']:\n",
    "            y_pred_thresh.append(pred)\n",
    "\n",
    "\n",
    "    # Run through every prediction and assign an Object to it.\n",
    "    for box in y_pred_thresh:\n",
    "\n",
    "        # Get values from box\n",
    "        (_,_,xmin,ymin,xmax,ymax) = [int(val) for val in box]\n",
    "        bbox = np.array([xmin,ymin,xmax,ymax])\n",
    "        boxes_to_draw.append(bbox)\n",
    "        \n",
    "        update_create_objects(trackable_objects, bbox)\n",
    "\n",
    "    # After updating all objects. Create multitracker and track every object.\n",
    "    multitracker = cv2.MultiTracker_create()\n",
    "\n",
    "    assign_tracker_to_object(multitracker, trackable_objects, frame)\n",
    "    \n",
    "    return multitracker, boxes_to_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:19.856328Z",
     "start_time": "2019-05-15T13:02:19.850335Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_box_to_obj(obj, boxes_pred, taken_boxes):\n",
    "    \"\"\" Method assignes closest box to the object.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    obj : Trackable_object\n",
    "        Object needed to be assigned.\n",
    "    boxes_pred : np.array\n",
    "        Array of boxes, predicted by multitracker.\n",
    "    tacken_boxes : np.array\n",
    "        Array of 0 and 1. 0 indicates the box in not tacken. 1 indicates the box is tacken.\n",
    "   \n",
    "    Returns\n",
    "    -------\n",
    "    obj.box : np.array\n",
    "        Returns appropriate box location.\n",
    "        \n",
    "    \"\"\"\n",
    "    min_dist = parameters.get('min_dist')\n",
    "    cur_box = (0,0,0,0)\n",
    "    box_id = 1337\n",
    "\n",
    "    # Find closest box\n",
    "    for i in range(len(boxes_pred)): \n",
    "        if taken_boxes[i] == 0:\n",
    "            cur_dist = get_ang_dist(box_from_roi(boxes_pred[i]), obj.future_box)\n",
    "            if cur_dist < min_dist:\n",
    "                min_dist = cur_dist\n",
    "                obj.has_assigned_box = True\n",
    "                cur_box = boxes_pred[i]\n",
    "                box_id = i\n",
    "\n",
    "    # Assign box to object is found\n",
    "    if obj.has_assigned_box:\n",
    "        obj.update(obj.ttl, obj.is_tracked, (cur_box[0],cur_box[1],cur_box[0]+cur_box[2],cur_box[1]+cur_box[3]))\n",
    "        taken_boxes[box_id] = 1\n",
    "\n",
    "        \n",
    "    return obj.box      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:20.125250Z",
     "start_time": "2019-05-15T13:02:20.106243Z"
    }
   },
   "outputs": [],
   "source": [
    "def track(frame, multitracker,trackable_objects): \n",
    "    \"\"\" Method trackes objects in the frame.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    frame : Image\n",
    "        Current frame of the video.\n",
    "    multitracker : cv2.Multitracker\n",
    "        Multitracker object to predict positions.\n",
    "    trackable_objects : dict\n",
    "        Dictionary of trackable objects.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    objects_to_draw : list\n",
    "        List of tuples (ID, BOX). May be used for visualization.\n",
    "        \n",
    "    \"\"\"\n",
    "    status = 'Tracking'\n",
    "\n",
    "    # Get boxes from tracekrs\n",
    "    (success, boxes_pred) = multitracker.update(frame)\n",
    "\n",
    "    for (object_id, obj) in trackable_objects.items():\n",
    "        obj.has_assigned_box = False\n",
    "\n",
    "    # Array to handle 1-1 box-object\n",
    "    taken_boxes = np.zeros(len(boxes_pred))\n",
    "\n",
    "    boxes_pred = np.array(boxes_pred)\n",
    "    boxes_pred = boxes_pred.astype(int)\n",
    "\n",
    "    objects_to_draw = []\n",
    "    # Assign box for each object\n",
    "    for (object_id, obj) in trackable_objects.items():\n",
    "        if obj.ttl > 0:\n",
    "            o_box = assign_box_to_obj(obj, boxes_pred, taken_boxes)\n",
    "            objects_to_draw.append((obj.object_id, o_box))\n",
    "            \n",
    "            \n",
    "    return objects_to_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:20.525172Z",
     "start_time": "2019-05-15T13:02:20.516178Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw(to_show, to_save, frame, frames_processed, boxes_to_draw, objects_to_draw):\n",
    "    \"\"\"Show or Save frame.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    to_show : bool\n",
    "        Indicates the need in showing the frame.\n",
    "    to_save : bool\n",
    "        Indicates the need in saving the frame.\n",
    "    frame : Image\n",
    "        Current frame of the video.\n",
    "    frames_processed : int\n",
    "        Number of the current frame\n",
    "    boxes_to_draw : list\n",
    "        List of boxes to visualize.\n",
    "    objects_to_draw : list\n",
    "        List of object boxes to visualize.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    for box in boxes_to_draw:\n",
    "        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 2)\n",
    "\n",
    "    for i, box in objects_to_draw:\n",
    "        cv2.putText(frame, '%d'%(i), (box[0],box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(25,111,255),2)\n",
    "        cv2.rectangle(frame,(box[0],box[1]),(box[2],box[3]),(0,0,255),2)\n",
    "       \n",
    "    cv2.putText(frame, 'Frame: '+str(frames_processed), (10,40), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,255),1)\n",
    "    \n",
    "    if to_show:\n",
    "        cv2.imshow('Frame', frame)\n",
    "    if to_save:\n",
    "        out.write(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:21.749780Z",
     "start_time": "2019-05-15T13:02:21.745788Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_vs():\n",
    "    # if a video path was not supplied, grab the reference to the web cam\n",
    "    if not parameters.get('video', False):\n",
    "        print(\"[INFO] starting video stream...\")\n",
    "        vs = VideoStream(src=0).start()\n",
    "        time.sleep(1.0)\n",
    " \n",
    "    # otherwise, grab a reference to the video file\n",
    "    else:\n",
    "        vs = cv2.VideoCapture(parameters['video'])\n",
    "    return vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:02:22.203621Z",
     "start_time": "2019-05-15T13:02:22.195166Z"
    }
   },
   "outputs": [],
   "source": [
    "def track_objects_in_video(to_show, to_save):\n",
    "    \"\"\" General method to run object tracking.\n",
    "    Parameters\n",
    "    -------\n",
    "    to_show : bool\n",
    "        Indicates the need in showing the frame.\n",
    "    to_save : bool\n",
    "        Indicates the need in saving the frame.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    vs = init_vs()\n",
    "\n",
    "    trackable_objects = {} # dict of trackable objects 'id':TrackableObject\n",
    "    frames_processed = 0\n",
    "    multitracker = cv2.MultiTracker_create()\n",
    "    objects_to_draw = []\n",
    "    \n",
    "    if to_save:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter('output_0.avi',fourcc, 24.0, (300,300))\n",
    "\n",
    "    \n",
    "    while True:\n",
    "         # get the frame\n",
    "        frame = vs.read()\n",
    "        frame = frame[1] if parameters.get(\"video\", False) else frame\n",
    "\n",
    "        # if no frame -> break\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        # resize frame to fit into SSD\n",
    "        frame = cv2.resize(frame,(300,300))\n",
    "\n",
    "        \n",
    "\n",
    "        if frames_processed % parameters['frame_skip'] == 0:\n",
    "            # Detect\n",
    "            multitracke, boxes_to_draw = detect(frame, trackable_objects)\n",
    "        else:\n",
    "            # Track\n",
    "            objects_to_draw = track(frame,multitracker,trackable_objects)\n",
    "\n",
    "            \n",
    "        # Draw\n",
    "        draw(to_show,to_save, frame, frames_processed, boxes_to_draw, objects_to_draw)\n",
    "        \n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "        frames_processed+=1\n",
    "\n",
    "    if to_save:\n",
    "        out.release()\n",
    "        \n",
    "    vs.release()     \n",
    "    cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T13:03:36.144405Z",
     "start_time": "2019-05-15T13:02:24.394512Z"
    }
   },
   "outputs": [],
   "source": [
    "track_objects_in_video(to_show=True, to_save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
